---
entries:
  - id: 0
    lab: "Singh Lab"
    location: "Brown University, Providence, RI"
    timePeriod: "Sep '25 – Present"
    role: "Research Assistant"
    skills:
      - text: python
        bgColor: '#3A78A9'
        textColor: '#FEDE57'
      - text: pytorch
        bgColor: '#F1F3F4'
        textColor: '#F55130'
      - text: graph neural networks
        bgColor: '#6366F1'
        textColor: '#FFFFFF'
      - text: knowledge graphs
        bgColor: '#10B981'
        textColor: '#FFFFFF'
      - text: computational biology
        bgColor: '#EF4444'
        textColor: '#FFFFFF'
    description: |
      • Enhanced a **graph-based deep learning** framework to uncover novel therapeutic targets for clinical drugs discontinued for non-safety reasons
      
      • Integrated heterogeneous biomedical knowledge graphs (**DrugBank**, **DDInter**, **PharmaDB**, **Hetionet**) for drug-gene-disease networks
      
      • Currently collaborating with biologists at the **NIH** and **NCI** to validate predictions with experimental oncology data

  - id: 1
    lab: "HIPS – Independent Research"
    location: "Brown University, Providence, RI"
    timePeriod: "Ongoing 2025"
    role: "Research Project"
    skills:
      - text: python
        bgColor: '#3A78A9'
        textColor: '#FEDE57'
      - text: pytorch
        bgColor: '#F1F3F4'
        textColor: '#F55130'
      - text: transformers
        bgColor: '#FF6B6B'
        textColor: '#FFFFFF'
      - text: single-cell RNA-seq
        bgColor: '#4ECDC4'
        textColor: '#FFFFFF'
      - text: computational biology
        bgColor: '#EF4444'
        textColor: '#FFFFFF'
    description: |
      • Developing a **hierarchical transformer** framework to model disease progression in large-scale single-nucleus datasets (~1.3M cells × 36K genes) from the **Allen Institute's SEA-AD** initiative
      
      • Extending **foundation models** with multi-scale attention mechanisms to learn biologically meaningful representations across cell types and cortical regions
      
      • Independent research project initiated as a class challenge and continued independently

  - id: 2
    lab: "Human Robotics Lab"
    location: "King's College London, London, UK"
    timePeriod: "May 2024"
    role: "First Class Dissertation Project"
    skills:
      - text: python
        bgColor: '#3A78A9'
        textColor: '#FEDE57'
      - text: pytorch
        bgColor: '#F1F3F4'
        textColor: '#F55130'
      - text: affine optical flow
        bgColor: '#10B981'
        textColor: '#FFFFFF'
      - text: sparse representation
        bgColor: '#6366F1'
        textColor: '#FFFFFF'
      - text: noise2noise CNN
        bgColor: '#EF4444'
        textColor: '#FFFFFF'
      - text: medical imaging
        bgColor: '#F59E0B'
        textColor: '#FFFFFF'
    description: |
      • Developed a **zero-shot Noise2Noise CNN** to automate B-mode ultrasound preprocessing, boosting accuracy by **11%**
      
      • Tracked fascicle motion across serial B-mode frames using **affine optical flow** and **sparse representations**, improving temporal consistency and reducing segmentation drift
      
      • Replaced legacy clinical software (**UltraTrack**) in downstream analysis at King's College London. Supervised by **Dr Letizia Gionfrida** in the Human Robotics Lab at KCL

---
